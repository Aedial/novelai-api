
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>novelai_api.Tokenizer &#8212; NovelAI API 0.25.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/classic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/micromodal.css" />
    
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/hoverxref.js"></script>
    <script src="../../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../../_static/js/micromodal.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">NovelAI API 0.25.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">novelai_api.Tokenizer</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for novelai_api.Tokenizer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">sentencepiece</span>
<span class="kn">import</span> <span class="nn">tokenizers</span>

<span class="kn">from</span> <span class="nn">novelai_api.ImagePreset</span> <span class="kn">import</span> <span class="n">ImageModel</span>
<span class="kn">from</span> <span class="nn">novelai_api.Preset</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">novelai_api.tokenizers.simple_tokenizer</span> <span class="kn">import</span> <span class="n">SimpleTokenizer</span>

<span class="n">AnyModel</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">Model</span><span class="p">,</span> <span class="n">ImageModel</span><span class="p">]</span>

<span class="n">tokenizers_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s2">&quot;tokenizers&quot;</span>


<div class="viewcode-block" id="SentencePiece"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.SentencePiece">[docs]</a><span class="k">class</span> <span class="nc">SentencePiece</span><span class="p">(</span><span class="n">sentencepiece</span><span class="o">.</span><span class="n">SentencePieceProcessor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper around sentencepiece.SentencePieceProcessor that adds the encode and decode methods</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">trans_table_ids</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
    <span class="n">trans_table_str</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>
    <span class="n">trans_regex_str</span><span class="p">:</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span>

<div class="viewcode-block" id="SentencePiece.__init__"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.SentencePiece.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trans_table_ids</span> <span class="o">=</span> <span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unk_id</span><span class="p">():</span> <span class="s2">&quot;&lt;|unk|&gt;&quot;</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pad_id</span><span class="p">():</span> <span class="s2">&quot;&lt;|pad|&gt;&quot;</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bos_id</span><span class="p">():</span> <span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eos_id</span><span class="p">():</span> <span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trans_table_str</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;&lt;|unk|&gt;&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_id</span><span class="p">(),</span>
            <span class="s2">&quot;&lt;|pad|&gt;&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_id</span><span class="p">(),</span>
            <span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bos_id</span><span class="p">(),</span>
            <span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos_id</span><span class="p">(),</span>
        <span class="p">}</span>

        <span class="n">trans_regex_keys</span> <span class="o">=</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trans_table_str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trans_regex_str</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">trans_regex_keys</span><span class="p">)</span></div>

<div class="viewcode-block" id="SentencePiece.encode"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.SentencePiece.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode the provided text using the SentencePiece tokenizer.</span>
<span class="sd">        This workaround is needed because sentencepiece cannot handle some tokens</span>

<span class="sd">        :param s: Text to encode</span>

<span class="sd">        :return: List of tokens the provided text encodes into</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">trans_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trans_table_str</span>

        <span class="c1"># find the indexes of the string that need to be replaced</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans_regex_str</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

        <span class="c1"># fast path, no translation needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">indexes</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">EncodeAsIds</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

        <span class="c1"># split the tokens into parts, using the indexes as separators and decode them</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">s</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="n">indexes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">start</span><span class="p">()],</span>
            <span class="o">*</span><span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">end</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">j</span><span class="o">.</span><span class="n">start</span><span class="p">()]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">indexes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])],</span>
            <span class="n">s</span><span class="p">[</span><span class="n">indexes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">end</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:],</span>
        <span class="p">]</span>
        <span class="n">encoded_parts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">EncodeAsIds</span><span class="p">(</span><span class="n">part</span><span class="p">)</span> <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">parts</span><span class="p">]</span>

        <span class="c1"># translate the junctions</span>
        <span class="n">junctions</span> <span class="o">=</span> <span class="p">[</span><span class="n">trans_table</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indexes</span><span class="p">]</span>

        <span class="c1"># join the parts with the translated tokens</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="o">*</span><span class="n">encoded_parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="o">*</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">j</span><span class="p">,</span> <span class="o">*</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">junctions</span><span class="p">,</span> <span class="n">encoded_parts</span><span class="p">[</span><span class="mi">1</span><span class="p">:])),</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="SentencePiece.decode"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.SentencePiece.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decode the provided tokens using the SentencePiece tokenizer.</span>
<span class="sd">        This workaround is needed because sentencepiece cannot handle some tokens</span>

<span class="sd">        :param t: Tokens to decode</span>

<span class="sd">        :return: Text the provided tokens decode into</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">trans_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trans_table_ids</span>

        <span class="c1"># find the indexes of the string that need to be replaced</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">trans_table</span><span class="p">]</span>

        <span class="c1"># fast path, no translation needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">indexes</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">DecodeIds</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

        <span class="c1"># split the tokens into parts, using the indexes as separators and decode them</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">t</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="n">indexes</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="o">*</span><span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">indexes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])],</span>
            <span class="n">t</span><span class="p">[</span><span class="n">indexes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:],</span>
        <span class="p">]</span>
        <span class="n">decoded_parts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">DecodeIds</span><span class="p">(</span><span class="n">part</span><span class="p">)</span> <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">parts</span><span class="p">]</span>

        <span class="c1"># translate the junctions</span>
        <span class="n">junctions</span> <span class="o">=</span> <span class="p">[</span><span class="n">trans_table</span><span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indexes</span><span class="p">]</span>

        <span class="c1"># join the parts with the translated tokens</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">((</span><span class="n">decoded_parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">junctions</span><span class="p">,</span> <span class="n">decoded_parts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))))</span></div></div>


<div class="viewcode-block" id="Tokenizer"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.Tokenizer">[docs]</a><span class="k">class</span> <span class="nc">Tokenizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstraction of the tokenizer behind each Model</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_tokenizers_name</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Model.Calliope:             &quot;gpt2&quot;,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Sigurd</span><span class="p">:</span> <span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Euterpe</span><span class="p">:</span> <span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Krake</span><span class="p">:</span> <span class="s2">&quot;pile&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Snek</span><span class="p">:</span> <span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Genji</span><span class="p">:</span> <span class="s2">&quot;gpt2-genji&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">HypeBot</span><span class="p">:</span> <span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Inline</span><span class="p">:</span> <span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Clio</span><span class="p">:</span> <span class="s2">&quot;nerdstash_v1&quot;</span><span class="p">,</span>
        <span class="n">Model</span><span class="o">.</span><span class="n">Kayra</span><span class="p">:</span> <span class="s2">&quot;nerdstash_v2&quot;</span><span class="p">,</span>
        <span class="n">ImageModel</span><span class="o">.</span><span class="n">Anime_Curated</span><span class="p">:</span> <span class="s2">&quot;clip&quot;</span><span class="p">,</span>
        <span class="n">ImageModel</span><span class="o">.</span><span class="n">Anime_Full</span><span class="p">:</span> <span class="s2">&quot;clip&quot;</span><span class="p">,</span>
        <span class="n">ImageModel</span><span class="o">.</span><span class="n">Furry</span><span class="p">:</span> <span class="s2">&quot;clip&quot;</span><span class="p">,</span>
    <span class="p">}</span>

<div class="viewcode-block" id="Tokenizer.get_tokenizer_name"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.Tokenizer.get_tokenizer_name">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_tokenizer_name</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the tokenizer name a model uses</span>

<span class="sd">        :param model: Model to get the tokenizer name of</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_tokenizers_name</span><span class="p">[</span><span class="n">model</span><span class="p">]</span></div>

    <span class="n">_GPT2_PATH</span> <span class="o">=</span> <span class="n">tokenizers_path</span> <span class="o">/</span> <span class="s2">&quot;gpt2_tokenizer.json&quot;</span>
    <span class="n">_GPT2_TOKENIZER</span> <span class="o">=</span> <span class="n">tokenizers</span><span class="o">.</span><span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">_GPT2_PATH</span><span class="p">))</span>

    <span class="n">_GENJI_PATH</span> <span class="o">=</span> <span class="n">tokenizers_path</span> <span class="o">/</span> <span class="s2">&quot;gpt2-genji_tokenizer.json&quot;</span>
    <span class="n">_GENJI_TOKENIZER</span> <span class="o">=</span> <span class="n">tokenizers</span><span class="o">.</span><span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">_GENJI_PATH</span><span class="p">))</span>

    <span class="n">_PILE_PATH</span> <span class="o">=</span> <span class="n">tokenizers_path</span> <span class="o">/</span> <span class="s2">&quot;pile_tokenizer.json&quot;</span>
    <span class="n">_PILE_TOKENIZER</span> <span class="o">=</span> <span class="n">tokenizers</span><span class="o">.</span><span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">_PILE_PATH</span><span class="p">))</span>

    <span class="c1"># TODO: check differences from NAI tokenizer (from my limited testing, there is None)</span>
    <span class="n">_CLIP_TOKENIZER</span> <span class="o">=</span> <span class="n">SimpleTokenizer</span><span class="p">()</span>

    <span class="n">_NERDSTASH_TOKENIZER_v1_PATH</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">tokenizers_path</span> <span class="o">/</span> <span class="s2">&quot;nerdstash_v1.model&quot;</span><span class="p">)</span>
    <span class="n">_NERDSTASH_TOKENIZER_v1</span> <span class="o">=</span> <span class="n">SentencePiece</span><span class="p">(</span><span class="n">_NERDSTASH_TOKENIZER_v1_PATH</span><span class="p">)</span>

    <span class="n">_NERDSTASH_TOKENIZER_v2_PATH</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">tokenizers_path</span> <span class="o">/</span> <span class="s2">&quot;nerdstash_v2.model&quot;</span><span class="p">)</span>
    <span class="n">_NERDSTASH_TOKENIZER_v2</span> <span class="o">=</span> <span class="n">SentencePiece</span><span class="p">(</span><span class="n">_NERDSTASH_TOKENIZER_v2_PATH</span><span class="p">)</span>

    <span class="n">_tokenizers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;gpt2&quot;</span><span class="p">:</span> <span class="n">_GPT2_TOKENIZER</span><span class="p">,</span>
        <span class="s2">&quot;gpt2-genji&quot;</span><span class="p">:</span> <span class="n">_GENJI_TOKENIZER</span><span class="p">,</span>
        <span class="s2">&quot;pile&quot;</span><span class="p">:</span> <span class="n">_PILE_TOKENIZER</span><span class="p">,</span>
        <span class="s2">&quot;clip&quot;</span><span class="p">:</span> <span class="n">_CLIP_TOKENIZER</span><span class="p">,</span>
        <span class="s2">&quot;nerdstash_v1&quot;</span><span class="p">:</span> <span class="n">_NERDSTASH_TOKENIZER_v1</span><span class="p">,</span>
        <span class="s2">&quot;nerdstash_v2&quot;</span><span class="p">:</span> <span class="n">_NERDSTASH_TOKENIZER_v2</span><span class="p">,</span>
    <span class="p">}</span>

<div class="viewcode-block" id="Tokenizer.decode"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.Tokenizer.decode">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">AnyModel</span><span class="p">,</span> <span class="n">o</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decode the provided tokens using the chosen tokenizer</span>

<span class="sd">        :param model: Model to use the tokenizer of</span>
<span class="sd">        :param o: List of tokens to decode</span>

<span class="sd">        :return: Text the provided tokens decode into</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tokenizer_name</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_tokenizers_name</span><span class="p">[</span><span class="n">model</span><span class="p">]</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_tokenizers</span><span class="p">[</span><span class="n">tokenizer_name</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">o</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tokenizer.encode"><a class="viewcode-back" href="../../novelai_api/novelai_api.Tokenizer.html#novelai_api.Tokenizer.Tokenizer.encode">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">AnyModel</span><span class="p">,</span> <span class="n">o</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode the provided text using the chosen tokenizer</span>

<span class="sd">        :param model: Model to use the tokenizer of</span>
<span class="sd">        :param o: Text to encode</span>

<span class="sd">        :return: List of tokens the provided text encodes into</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tokenizer_name</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_tokenizers_name</span><span class="p">[</span><span class="n">model</span><span class="p">]</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_tokenizers</span><span class="p">[</span><span class="n">tokenizer_name</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenizers</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">o</span><span class="p">)</span><span class="o">.</span><span class="n">ids</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="p">(</span><span class="n">SimpleTokenizer</span><span class="p">,</span> <span class="n">sentencepiece</span><span class="o">.</span><span class="n">SentencePieceProcessor</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>

        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer </span><span class="si">{</span><span class="n">tokenizer</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">tokenizer_name</span><span class="si">}</span><span class="s2">) not recognized&quot;</span><span class="p">)</span></div></div>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">NovelAI API 0.25.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">novelai_api.Tokenizer</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2024, Aedial.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    </div>
  </body>
</html>